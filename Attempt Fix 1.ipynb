{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9e56904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import Dict, Union\n",
    "\n",
    "def load_data_create_dict(input_dim: int, \n",
    "                          use_pseudorehearsal: bool , \n",
    "                          optimizer: str , \n",
    "                          trials: int , \n",
    "                          num_models: int) -> Dict[str, Union[np.ndarray, None]]:\n",
    "    \"\"\"\n",
    "    Load data for specified trials and models from a structured directory and \n",
    "    return it as a dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    input_dim : int\n",
    "        Input dimension.\n",
    "    use_pseudorehearsal : bool\n",
    "        Whether pseudo rehearsal is used.\n",
    "    optimizer : str\n",
    "        Type of optimizer ('sgd', etc.).\n",
    "    trials : int\n",
    "        Number of trials.\n",
    "    num_models : int\n",
    "        Number of models.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary containing concatenated min and max distances and model \n",
    "        perturbations for each trial and model.\n",
    "    \"\"\"\n",
    "    \n",
    "    base_folder = f\"results/input_dim_{input_dim}_{use_pseudorehearsal}_{optimizer}\"\n",
    "\n",
    "    # Initialize the dictionary with keys for min_distance, max_distance, and model perturbations\n",
    "    data = {\n",
    "        \"min_distance\": [],\n",
    "        \"max_distance\": [],\n",
    "        **{f\"model_{j}_perturbations\": [] for j in range(num_models)}\n",
    "    }\n",
    "\n",
    "    for i in range(trials):\n",
    "        trial_folder = f\"{base_folder}/trial_{i}\"\n",
    "\n",
    "        paths = {\n",
    "            \"min_distance\": f\"{trial_folder}/distances/min_distances.npy\",\n",
    "            \"max_distance\": f\"{trial_folder}/distances/max_distances.npy\",\n",
    "            **{f\"model_{j}_perturbations\": f\"{trial_folder}/perturbations/model_{j}/absolute_perturbation.npy\" for j in range(num_models)}\n",
    "        }\n",
    "\n",
    "        for key, path in paths.items():\n",
    "            if os.path.exists(path):\n",
    "                data[key].append(np.load(path))\n",
    "            else:\n",
    "                print(f\"Warning: {path} not found.\")\n",
    "\n",
    "    # Convert lists of numpy arrays to a single concatenated numpy array\n",
    "    for key, value in data.items():\n",
    "        data[key] = np.concatenate(value, axis=0).flatten() if value else None\n",
    "                \n",
    "    return data\n",
    "\n",
    "def save_aggregated_data(input_dim: int, \n",
    "                         use_pseudorehearsal: bool, \n",
    "                         optimizer: str, \n",
    "                         trials: int, \n",
    "                         num_models: int) -> None:\n",
    "    \"\"\"\n",
    "    Save aggregated data to a numpy file for specified parameters.\n",
    "\n",
    "    The function aggregates data based on the provided parameters and \n",
    "    saves it in a structured directory named 'aggregated_results'.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    input_dim : int\n",
    "        Input dimension.\n",
    "    use_pseudorehearsal : bool\n",
    "        Whether pseudo rehearsal is used.\n",
    "    optimizer : str\n",
    "        Type of optimizer ('sgd', etc.).\n",
    "    trials : int\n",
    "        Number of trials. Aggregation is done over 0 to this parameter the (max) number of trials\n",
    "    num_models : int\n",
    "        Number of models.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    base_folder = f\"results/input_dim_{input_dim}_{use_pseudorehearsal}_{optimizer}\"\n",
    "\n",
    "    # Save the data\n",
    "    save_folder = \"aggregated_results\"\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    save_path = f\"{save_folder}/input_dim_{input_dim}_{use_pseudorehearsal}_{optimizer}.npy\"\n",
    "    \n",
    "    # Fetch the aggregated data\n",
    "    data = load_data_create_dict(input_dim, use_pseudorehearsal, optimizer, trials, num_models)\n",
    "    \n",
    "    # Save the data to the specified path\n",
    "    np.save(save_path, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3f1deb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_data \n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m loaded_data_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_all_aggregated_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 15\u001b[0m, in \u001b[0;36mload_all_aggregated_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(save_folder) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Extract the configuration details from the file name using regex\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_dim_(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)_(True|False)_(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+).npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m     18\u001b[0m     match \u001b[38;5;241m=\u001b[39m pattern\u001b[38;5;241m.\u001b[39mmatch(file)\n",
      "\u001b[1;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "def load_all_aggregated_data() -> dict:\n",
    "    \"\"\"Load all aggregated data for various configurations: input dimensions, pseudo rehearsal, and optimizer.\n",
    "    \n",
    "    Returns:\n",
    "    - all_data (dict): A nested dictionary with keys as input dimensions, pseudorehearsal, and optimizer \n",
    "                       and values as the loaded data.\n",
    "    \"\"\"\n",
    "    all_data = {}\n",
    "    save_folder = \"aggregated_results\"\n",
    "    \n",
    "    # Get all files in the folder with the .npy extension\n",
    "    files = [f for f in os.listdir(save_folder) if f.endswith(\".npy\")]\n",
    "\n",
    "    # Extract the configuration details from the file name using regex\n",
    "    pattern = re.compile(r\"input_dim_(\\d+)_(True|False)_(\\w+).npy\")\n",
    "\n",
    "    for file in files:\n",
    "        match = pattern.match(file)\n",
    "        if match:\n",
    "            dim = int(match.group(1))\n",
    "            pseudo_rehearsal = True if match.group(2) == 'True' else False\n",
    "            optimizer = match.group(3)\n",
    "            \n",
    "            if dim not in all_data:\n",
    "                all_data[dim] = {}\n",
    "            \n",
    "            if pseudo_rehearsal not in all_data[dim]:\n",
    "                all_data[dim][pseudo_rehearsal] = {}\n",
    "            \n",
    "            save_path = os.path.join(save_folder, file)\n",
    "            data = np.load(save_path, allow_pickle=True).item()\n",
    "            all_data[dim][pseudo_rehearsal][optimizer] = data\n",
    "\n",
    "    return all_data \n",
    "\n",
    "# Example usage:\n",
    "loaded_data_dict = load_all_aggregated_data()\n",
    "#for dim, pseudo_rehearsal_data in loaded_data_dict.items():\n",
    "#    for pseudo, optimizer_data in pseudo_rehearsal_data.items():\n",
    "#        for optimizer, data in optimizer_data.items():\n",
    "#            print(f\"Data for dimension {dim}, pseudorehearsal: {pseudo}, optimizer: {optimizer} has keys: \\n\\n {data.keys()} \\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c8d768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b270e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is an example of how the aggregate function runs:\n",
    "\n",
    "max_num_trials = 3\n",
    "trial_chunks = 1\n",
    "\n",
    "optimizers = ['adam', 'sgd']\n",
    "pseudorehearsals = [True, False]\n",
    "input_dimensions = [x for x in range(1,3)]\n",
    "trial_numbers = list(range(max_num_trials))\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    for use_pseudorehearsal in pseudorehearsals:\n",
    "        for input_dimension in input_dimensions:\n",
    "            save_aggregated_data(input_dim=input_dimension,\n",
    "                                   use_pseudorehearsal=use_pseudorehearsal,\n",
    "                                   optimizer=optimizer,\n",
    "                                   trials=max_num_trials,\n",
    "                                   num_models=19)\n",
    "            \n",
    "            \n",
    "# here is a flawed version of a procedure that loads the saved data. It does not correctly incorporate\n",
    "# the True/False for pseudorehearsal or choice of optimizer. Can you please fix it?\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import re\n",
    "\n",
    "def load_all_aggregated_data() -> dict:\n",
    "    \"\"\"Load all aggregated data for all available input dimensions.\n",
    "    \n",
    "    Returns:\n",
    "    - all_data (dict): A dictionary with keys as input dimensions and values as the loaded data.\n",
    "    \"\"\"\n",
    "    all_data = {}\n",
    "    save_folder = \"aggregated_results\"\n",
    "    \n",
    "    # Get all files in the folder with the .npy extension\n",
    "    files = [f for f in os.listdir(save_folder) if f.endswith(\".npy\")]\n",
    "\n",
    "    # Extract the dimension from the file name using regex\n",
    "    pattern = re.compile(r\"data_input_dim_(\\d+).npy\")\n",
    "\n",
    "    for file in files:\n",
    "        match = pattern.match(file)\n",
    "        if match:\n",
    "            dim = int(match.group(1))\n",
    "            save_path = os.path.join(save_folder, file)\n",
    "            data = np.load(save_path, allow_pickle=True).item()\n",
    "            all_data[dim] = data\n",
    "\n",
    "    return all_data \n",
    "\n",
    "# Example usage:\n",
    "loaded_data_dict = load_all_aggregated_data()\n",
    "#for dim, data in loaded_data_dict.items():\n",
    "#    print(f\"Data for dimension {dim} has keys: \\n\\n {data.keys()} \\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dec493c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_distance': array([0.20778511, 0.08144092, 0.14693758, ..., 0.11785191, 0.00768984,\n",
       "        0.31310558]),\n",
       " 'max_distance': array([0.68519141, 0.24297593, 0.35712052, ..., 0.900284  , 0.41372856,\n",
       "        0.49212958]),\n",
       " 'model_0_perturbations': array([0.00190884, 0.22155362, 0.3145011 , ..., 0.08296591, 0.52713037,\n",
       "        0.07892662], dtype=float32),\n",
       " 'model_1_perturbations': array([0.05734289, 0.44299692, 0.23997849, ..., 0.07589984, 0.24677038,\n",
       "        0.05254287], dtype=float32),\n",
       " 'model_2_perturbations': array([0.00638894, 0.06607694, 0.28800416, ..., 0.01812072, 0.0257414 ,\n",
       "        0.01433322], dtype=float32),\n",
       " 'model_3_perturbations': array([0.41618338, 0.41618338, 0.41618338, ..., 0.08304958, 0.08304958,\n",
       "        0.08304958], dtype=float32),\n",
       " 'model_4_perturbations': array([0.0363976 , 0.34662816, 0.12458075, ..., 0.03423108, 0.05732498,\n",
       "        0.02507427], dtype=float32),\n",
       " 'model_5_perturbations': array([0.41618338, 0.41618338, 0.41618338, ..., 0.08304958, 0.08304958,\n",
       "        0.08304958], dtype=float32),\n",
       " 'model_6_perturbations': array([0.0187305 , 0.2924962 , 0.01034808, ..., 0.02279042, 0.05469296,\n",
       "        0.02156414], dtype=float32),\n",
       " 'model_7_perturbations': array([0.08253945, 0.17273659, 0.01810898, ..., 0.01464925, 0.0500564 ,\n",
       "        0.01397917], dtype=float32),\n",
       " 'model_8_perturbations': array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " 'model_9_perturbations': array([0.13625672, 0.15196167, 0.03468366, ..., 0.00886963, 0.06951588,\n",
       "        0.01570729], dtype=float32),\n",
       " 'model_10_perturbations': array([0.03231352, 0.0500265 , 0.0437039 , ..., 0.00666907, 0.08998132,\n",
       "        0.00829693], dtype=float32),\n",
       " 'model_11_perturbations': array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " 'model_12_perturbations': array([0.03169392, 0.00941761, 0.06207239, ..., 0.02188717, 0.12234898,\n",
       "        0.01282962], dtype=float32),\n",
       " 'model_13_perturbations': array([0.00769036, 0.01528043, 0.00992102, ..., 0.0019754 , 0.07479395,\n",
       "        0.00227159], dtype=float32),\n",
       " 'model_14_perturbations': array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " 'model_15_perturbations': array([0.01087476, 0.02963446, 0.01641786, ..., 0.00393296, 0.08895549,\n",
       "        0.00441377], dtype=float32),\n",
       " 'model_16_perturbations': array([0.00470636, 0.01007856, 0.00720944, ..., 0.00121711, 0.06114054,\n",
       "        0.0012509 ], dtype=float32),\n",
       " 'model_17_perturbations': array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " 'model_18_perturbations': array([0.00595404, 0.01628071, 0.01164306, ..., 0.00298355, 0.07522953,\n",
       "        0.00277398], dtype=float32)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data_create_dict(input_dim=2, use_pseudorehearsal=True, optimizer='adam', trials=3, num_models=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c725c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
